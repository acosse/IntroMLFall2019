{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 5: Introduction to neural Networks (part II)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you are more familiar with neural networks and some of their limitations, we will first build one from scratch. \n",
    "\n",
    "Then we will use Keras to handle more difficult datasets. Keras is a python library that runs on top of Tensor Flow and Theano. It comes with various implementations of neural network building blocks and it will give you more freedom in the design of your neural networks than Scikit-learn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 1__ We  go back to the XOR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import scipy.io as sio\n",
    "data1 = sio.loadmat('neural_net_class1.mat')\n",
    "data2 = sio.loadmat('neural_net_class2.mat')\n",
    "\n",
    "data1 = data1['neural_net_class1']\n",
    "data2 = data2['neural_net_class2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1a.__ For a single hidden layer and a fixed number of neurons, implement first a gradient descent on the log-loss function for \n",
    "\n",
    "- Linear activation functions\n",
    "- Relu's activation functions\n",
    "- sigmoid activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put the code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1b.__ Consider a smaller number of units. Let's say 10. And add one then two hidden layers. Use backpropagation to train the network on the log-loss function and compare your result to the results you obtained with the scikit implementation.   \n",
    "\n",
    "\n",
    "- Linear activation functions\n",
    "- Relu's activation functions\n",
    "- sigmoid activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put the code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 2.Moving to keras__ \n",
    "\n",
    "\n",
    "Capturing the spiral with more points. \n",
    "\n",
    "__2a.__ Consider the denser dataset given below. Plot it with scatter(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def twospirals(n_points, noise=.5):\n",
    "    \"\"\"\n",
    "     Returns the two spirals dataset.\n",
    "    \"\"\"\n",
    "    n = np.sqrt(np.random.rand(n_points,1)) * 780 * (2*np.pi)/360\n",
    "    d1x = -np.cos(n)*n + np.random.rand(n_points,1) * noise\n",
    "    d1y = np.sin(n)*n + np.random.rand(n_points,1) * noise\n",
    "    return (np.vstack((np.hstack((d1x,d1y)),np.hstack((-d1x,-d1y)))), \n",
    "            np.hstack((np.zeros(n_points),np.ones(n_points))))\n",
    "\n",
    "X, y = twospirals(1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2b.__Install Keras with pip or conda. Build a sequential model with 3 dense layers of size 12 and hyperbolic tangent activation functions. Set the input dimension to $2$ \n",
    "Finish the network by a single unit with sigmoid activation. \n",
    "\n",
    "- Set the compiler to minimize the binary cross entropy, use the RMSProp optimizer, and optimize the 'accuracy' metric \n",
    "\n",
    "- Fit the model to your spiral data using 150 epochs and a batch size of 10. Then apply it to the grid and plot the resulting contour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "# put your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 3. MNIST__\n",
    "\n",
    "__3a.__ Use the lines below to load the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mnist\n",
    "import keras\n",
    "\n",
    "# The first time you run this might be a bit slow, since the\n",
    "# mnist package has to download and cache the data.\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "\n",
    "print(train_images.shape) # (60000, 28, 28)\n",
    "print(train_labels.shape) # (60000,)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import mnist\n",
    "\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()\n",
    "\n",
    "# Normalize the images.\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "\n",
    "# Flatten the images.\n",
    "train_images = train_images.reshape((-1, 784))\n",
    "test_images = test_images.reshape((-1, 784))\n",
    "\n",
    "print(train_images.shape) # (60000, 784)\n",
    "print(test_images.shape)  # (10000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3b.__Build A sequential neural network with Keras that has \n",
    "\n",
    "- A first dense layer with 64 units and Relu activation function (set the input size to 'image_width x image_height') \n",
    "- A second dense layer of size 64 with Relu activation function \n",
    "- A last dense layer with softmax activation function. In your opinion, how many output units do we need? Why?\n",
    "\n",
    "Use 'Adam' as your optimizer with a categorical cross entropy loss and use 'accuracy' as the metric.\n",
    "\n",
    "Fit the model to the training data with a couple of epochs (less than 10) and a batch size of less than 50.\n",
    "\n",
    "Then look at your prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# put your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3c.__ Another important feature of Keras which is missing in scikit-learn is that it comes with an implementation of convolutional neural networks which are powerful architectures for image recognition. \n",
    "\n",
    "\n",
    "__I Understanding convolutions__ \n",
    "\n",
    "Take one of the mnist images. \n",
    "\n",
    "- Use numpy to compute its convolution with a gaussian filter and display the result \n",
    "- Change the filter to any other custom filter of your choice and repeat the first step.\n",
    "- Implement the [pooling operation](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/pooling_layer.html). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__II. __ In the code your wrote for MNIST, replace your structure with the following convolutional network\n",
    "\n",
    "- Take a sequential model that takes as input an image of size 28 by 28. \n",
    "- Take your first layer to be a 2D convolutional layer with 8 filters of size 3\n",
    "- Then add a Pooling layer (MaxPooling2D and set the poolsize parameter to 2). What does the pooling layer do?\n",
    "- Conclude with a dense layer with softmax activation function.\n",
    "\n",
    "\n",
    "Fit and test your model on the MNIST dataset. Don't forget to turn your original labels into categorical encodings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# put your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 4. Bonus__ Go online and download the Cats and dogs image. Try to build a convolutional neural network with Keras that classifies the images. You can check online documentation to get an intuition on the parameters you need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
